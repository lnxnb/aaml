{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "pwyjEt2KDbOs"
   },
   "outputs": [],
   "source": [
    "# this block of code imports graphical libraries for plotting graphs with high resolution\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi'] = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "MngkC29k1xTd"
   },
   "outputs": [],
   "source": [
    "# Libraries of functions need to be imported\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from scipy import linalg\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "# the following line(s) are necessary if you want to make SKlearn compliant functions\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6k7cQUEQ1alq"
   },
   "source": [
    "<font face=\"Avenir\" color=\"navy\" size=10>Intro to Locally Weighted Regression</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mfd4jt18WZTp"
   },
   "source": [
    "## Regression\n",
    "\n",
    "**Main Idea**:\n",
    " - the output (dependent) variable is continuous and we want to \"predict\" its value within the range of the input features. (<font color='red'>WARNING: doing otherwise could lead to flawed inferences</font>).\n",
    " - there is \"noise\" which means that for essentially the same input values there may be different slightly different values of the output variable or there is \"noise\" in the measurement of all the variables.  \n",
    " - we assume that the noise (i.e. the errors in measurement) are following a normal distribution with mean 0 and some unknown standard deviation.\n",
    "\n",
    "**Main Approach**:\n",
    "- we want to estimate the expected value of the dependent variable as a function of the input features. Thus we want to approximate a conditional expectation $\\mathbb{E}(y|\\text{input features})$ as a function of the input features such as $$\\mathbb{E}(y|X) = f(X)$$\n",
    "\n",
    "- we want to determine the simplest form of the function $f$ (principle of\n",
    "parsimony) and we assume that $$y = f(X) + \\sigma \\epsilon$$ where $\\epsilon$ is the \"noise\", in statistical terms, $\\epsilon$ is independent and identically distributed, it follows a standard normal distribution and, $\\sigma>0$ is generally unknown.\n",
    "\n",
    "## Linear Regression\n",
    "\n",
    "**Main Idea**: Make predictions as a weighted combination of the input feauture values; the weights can be positive or negative. Expressed as an intuitive equation the idea is as follows:\n",
    "\n",
    "$$\\text{Predicted Value} = weight_1 \\cdot \\text{Feature}_1 + weight_2 \\cdot \\text{Feature}_2 + ... + weight_p \\cdot \\text{Feature}_p $$\n",
    "\n",
    "<font color='darkred' size=4pt>Message: In Machine Learning the \"machine\" is learning the weights based on iterative processes. Typically, the updates are based on a gradient descent method for minimizing an objective function, such as the sum of squared errors.\n",
    "\n",
    "## Linear Regression\n",
    "\n",
    "The main idea of linear regression is the assumption that:\n",
    "\n",
    "$$\\large y = X\\cdot\\beta +\\sigma\\epsilon $$\n",
    "\n",
    "**Important aspect**: linear regression can be seen as a linear combination of the observed outputs (values of the dependent variable).\n",
    "\n",
    "We have:\n",
    "\n",
    "$$\\large  X^Ty = X^TX\\beta +\\sigma X^T\\epsilon$$\n",
    "\n",
    "We solve for $\\beta$ (by assuming that $X^TX$ is invertible):\n",
    "\n",
    "$$\\large \\beta = (X^TX)^{-1}(X^Ty) - \\sigma (X^TX)^{-1}X^T\\epsilon$$\n",
    "\n",
    "We take the expected value of this equation and obtain the expected value of the coeffcients:\n",
    "\n",
    "$$\\large \\bar{\\beta} = (X^TX)^{-1}(X^Ty)$$\n",
    "\n",
    "Therefore the predictions we make are:\n",
    "\n",
    "$$\\large \\hat{y} = X(X^TX)^{-1}(X^Ty)$$\n",
    "\n",
    "## Locally Weighted Regression\n",
    "\n",
    "**Main Idea:** Trends and associations are generally nonlinear; however, *locally*, trends can be interpreted linearly.\n",
    "\n",
    "In this context, local properties are relative to a metric. A metric is a method by which we compute the distance between two observations. Observations contain multiple features, and if they are numeric, we can see them as vectors in a finite-dimensional Euclidean space.\n",
    "\n",
    "The independent observations are the rows of the matrix $X$. Each row has a number of columns (this is the number of features) and we can denote it by $p.$ As such, every row is a vector in $\\mathbb{R}^p.$ The distance between two independent observations is the Euclidean distance between the two represented $p-$dimensional vectors. The equation is:\n",
    "\n",
    "$$ dist(\\vec{v},\\vec{w})=\\sqrt{(v_1-w_1)^2+(v_2-w_2)^2+...(v_p-w_p)^2}$$\n",
    "\n",
    "We shall have $n$ different weight vectors because we have $n$ different observations.\n",
    "\n",
    "## Visual Intuition\n",
    "\n",
    "<figure>\n",
    "<center>\n",
    "<img src=\"https://i.imgur.com/ycmCaN9.png\"\n",
    "width='500px' />\n",
    "<figcaption>Intuition for Locally Weighted Regression</figcaption></center>\n",
    "</figure>\n",
    "\n",
    "The message of this picture is that we are going to use kernels, such as Gaussian or similar shapes, for solving local linear regression problems.\n",
    "\n",
    "## A Framework Based on Linear Regression\n",
    "\n",
    "The main idea of linear regression is the assumption that:\n",
    "\n",
    "$$\\large y = X\\cdot\\beta +\\sigma\\epsilon $$\n",
    "\n",
    "If we pre-multiply this equation with a matrix of weights (the \"weights\" of observation $i$ are on the main diagonal and the rest of the elements are 0) we get:\n",
    "\n",
    "$$\\large \\text{diag}(W(i))y = \\text{diag}(W(i))X\\cdot\\beta +\\sigma \\text{diag}(W(i))\\epsilon $$\n",
    "\n",
    "The independent observations are the rows of the matrix $X$. Each row has a number of columns (this is the number of features) and we can denote it by $p.$ As such, every row is a vector in $\\mathbb{R}^p.$\n",
    "\n",
    "We shall have $n$ different weight vectors because we have $n$ different observations.\n",
    "\n",
    "**Important aspect**: linear regression can be seen as a linear combination of the observed outputs (values of the dependent variable). For convenience we can denote $\\text{diag}(W(i))$ by just $W.$\n",
    "\n",
    "We have:\n",
    "\n",
    "$$\\large  X^TWy = X^TWX\\beta +\\sigma X^TW\\epsilon$$\n",
    "\n",
    "We solve for $\\beta$ (by assuming that $X^TX$ is invertible):\n",
    "\n",
    "$$\\large \\beta = (X^TWX)^{-1}(X^TWy) - \\sigma (X^TX)^{-1}X^TW\\epsilon$$\n",
    "\n",
    "We take the expected value of this equation and obtain the expected value of the coeffcients:\n",
    "\n",
    "$$\\large \\bar{\\beta} = (X^TWX)^{-1}(X^TWy)$$\n",
    "\n",
    "Therefore the local predictions we make are:\n",
    "\n",
    "$$\\large \\hat{y} = X(X^TWX)^{-1}(X^TWy)$$\n",
    "\n",
    "In summary, locally weighted regression we have\n",
    "\n",
    "$$\\large \\hat{y} = X(X^TWX)^{-1}(X^TWy)$$\n",
    "\n",
    "The Big Idea: the predictions we make are a linear combination of the actual observed values of the dependent variable!\n",
    "\n",
    "For locally weighted regression, $\\hat{y}$ is obtained as a different linear combination of the values of y.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VN0gZPvRc7b0"
   },
   "source": [
    "\n",
    "The following animations are illustrative for how the locally weighte regression works (reference: scikit-lego docs):\n",
    "\n",
    "<figure>\n",
    "<center>\n",
    "<img src='https://drive.google.com/uc?id=1bQmo-j35etyEWt7Ce8TSo01YSOhZQBeY'width='800px'/>\n",
    "<figcaption>Example of how weights work</figcaption></center>\n",
    "</figure>\n",
    "\n",
    "\n",
    "<figure>\n",
    "<center>\n",
    "<img src='https://drive.google.com/uc?id=19cIIGCSePtJbGVgRT6uWhcV2tNJKe9WG'width='800px'/>\n",
    "<figcaption>Example of how locally weighted regression works</figcaption></center>\n",
    "</figure>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cz_g-Mm1d6DV"
   },
   "source": [
    "## Different Kernels\n",
    "\n",
    "Definition of the kernels: https://en.wikipedia.org/wiki/Kernel_(statistics)\n",
    "\n",
    "There are many choices of kernels for locally weighted regression. The idea is to have a function with one local maximum that has a compact support.\n",
    "\n",
    "1.   The Exponential (Gaussian) Kernel\n",
    "\n",
    "$$ K(x):= e^{-\\frac{\\|x\\|^2}{2\\tau}}$$\n",
    "\n",
    "\n",
    "2.   The Tricubic Kernel\n",
    "\n",
    "$$ K(x):=\\begin{cases}\n",
    "(1-\\|x\\|^3)^3 \\;\\;\\;if \\;\\;\\; \\|x\\|<1 \\\\\n",
    "0 \\;\\;\\; \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "3.   The Epanechnikov Kernel\n",
    "\n",
    "$$ K(x):=\\begin{cases}\n",
    "\\frac{3}{4}(1-\\|x\\|^2) \\;\\;\\;if \\;\\;\\; \\|x\\|<1 \\\\\n",
    "0 \\;\\;\\; \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "3.   The Quartic Kernel\n",
    "\n",
    "$$ K(x):=\\begin{cases}\n",
    "\\frac{15}{16}(1-\\|x\\|^2)^2 \\;\\;\\;if \\;\\;\\; \\|x\\|<1 \\\\\n",
    "0 \\;\\;\\; \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "pVJN1dFl1FH1"
   },
   "outputs": [],
   "source": [
    "# Gaussian Kernel\n",
    "def Gaussian(x):\n",
    "  return np.where(np.abs(x)>4,0,1/(np.sqrt(2*np.pi))*np.exp(-1/2*x**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "2rh_RP12cYwK"
   },
   "outputs": [],
   "source": [
    "# this is the correct vectorized version\n",
    "def tricubic(x):\n",
    "  return np.where(np.abs(x)>1,0,(1-np.abs(x)**3)**3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "4TtZzxpteCO0"
   },
   "outputs": [],
   "source": [
    "# Epanechnikov Kernel\n",
    "def Epanechnikov(x):\n",
    "  return np.where(np.abs(x)>1,0,3/4*(1-np.abs(x)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "lZ1rmjMfywSx"
   },
   "outputs": [],
   "source": [
    "# Quartic Kernel\n",
    "def Quartic(x):\n",
    "  return np.where(np.abs(x)>1,0,15/16*(1-np.abs(x)**2)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "1JNTsT84uZhi"
   },
   "outputs": [],
   "source": [
    "kernel = tricubic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "evrjf1rGuZhi"
   },
   "outputs": [],
   "source": [
    "def kernel_function(xi,x0,kern, tau):\n",
    "    return kern((xi - x0)/(2*tau))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ZgxvusoiuZhi"
   },
   "outputs": [],
   "source": [
    "def weights_matrix(x,kern,tau):\n",
    "  n = len(x)\n",
    "  return np.array([kernel_function(x,x[i],kern,tau) for i in range(n)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-5,5,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "C02K0MXLuZhi"
   },
   "outputs": [],
   "source": [
    "n = len(x)\n",
    "w = weights_matrix(x,kernel,0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "GSGXxtTZAMLf"
   },
   "outputs": [],
   "source": [
    "cars = pd.read_csv(\"mtcars.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "CYZHhzCoLgI4"
   },
   "outputs": [],
   "source": [
    "y = cars['mpg'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GKiTMziaL_k2",
    "outputId": "e1ad3cb7-e1ac-4017-fa9d-f413be0a42ec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([21. , 21. , 22.8, 21.4, 18.7, 18.1, 14.3, 24.4, 22.8, 19.2, 17.8,\n",
       "       16.4, 17.3, 15.2, 10.4, 10.4, 14.7, 32.4, 30.4, 33.9, 21.5, 15.5,\n",
       "       15.2, 13.3, 19.2, 27.3, 26. , 30.4, 15.8, 19.7, 15. , 21.4])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "v_mK_9PfMFOe"
   },
   "outputs": [],
   "source": [
    "x = cars.loc[:,'wt'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uS8coniWMQdN",
    "outputId": "74e8ed44-37bf-4ead-911c-75131145aee3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we check the dimensionality of X\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "b-d_Vgz_Mpyk"
   },
   "outputs": [],
   "source": [
    "XTX = np.transpose(x).dot(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hldcV9noNU8H"
   },
   "source": [
    "check if the $X^TX$ matrix is invertible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7c2GoxVqNeDj",
    "outputId": "06ee4573-416b-449e-f105-1d7ce26027a9"
   },
   "outputs": [
    {
     "ename": "LinAlgError",
     "evalue": "0-dimensional array given. Array must be at least two-dimensional",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39minv(XTX)\u001b[38;5;241m.\u001b[39mdot(np\u001b[38;5;241m.\u001b[39mtranspose(X)\u001b[38;5;241m.\u001b[39mdot(y))\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36minv\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/numpy/linalg/linalg.py:532\u001b[0m, in \u001b[0;36minv\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m    471\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;124;03mCompute the (multiplicative) inverse of a matrix.\u001b[39;00m\n\u001b[1;32m    473\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    529\u001b[0m \n\u001b[1;32m    530\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    531\u001b[0m a, wrap \u001b[38;5;241m=\u001b[39m _makearray(a)\n\u001b[0;32m--> 532\u001b[0m _assert_stacked_2d(a)\n\u001b[1;32m    533\u001b[0m _assert_stacked_square(a)\n\u001b[1;32m    534\u001b[0m t, result_t \u001b[38;5;241m=\u001b[39m _commonType(a)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/numpy/linalg/linalg.py:183\u001b[0m, in \u001b[0;36m_assert_stacked_2d\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m arrays:\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m a\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m--> 183\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LinAlgError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m-dimensional array given. Array must be \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    184\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mat least two-dimensional\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m a\u001b[38;5;241m.\u001b[39mndim)\n",
      "\u001b[0;31mLinAlgError\u001b[0m: 0-dimensional array given. Array must be at least two-dimensional"
     ]
    }
   ],
   "source": [
    "np.linalg.inv(XTX).dot(np.transpose(X).dot(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ICUiiY1eOEwJ"
   },
   "outputs": [],
   "source": [
    "# let's check\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VELdACwCOKTc"
   },
   "outputs": [],
   "source": [
    "model= LinearRegression(fit_intercept=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QWQ40jp3OXKd",
    "outputId": "75dbaa72-d5a4-4157-b136-872e4d54f7fe"
   },
   "outputs": [],
   "source": [
    "model.fit(x,y)\n",
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sLz21ArEuZQq"
   },
   "outputs": [],
   "source": [
    "cars = cars.sort_values(by='wt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VYpnMxPaYHTb"
   },
   "source": [
    "### This is he actual scatter plot connnecting weight and mileage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 528
    },
    "id": "rGcTHOmtb2nx",
    "outputId": "ffc6afa6-47f0-4f2d-d9c0-71168a285838"
   },
   "outputs": [],
   "source": [
    "# from matplotlib.figure import figaspect\n",
    "fig, ax = plt.subplots(1,1)\n",
    "ax.scatter(cars[\"wt\"],cars[\"mpg\"],color='deepskyblue',ec='k',alpha=0.7)\n",
    "plt.xlabel('Weight',fontsize=18)\n",
    "plt.ylabel('Miles Per Gallon',fontsize=18)\n",
    "ax.grid()\n",
    "plt.xlim(1,6)\n",
    "plt.ylim(5,40)\n",
    "ax.grid(which='major', color='#DDDDDD', linewidth=0.7)\n",
    "ax.grid(which='minor', color='#EEEEEE', linestyle=':', linewidth=0.7)\n",
    "ax.set_axisbelow(True)\n",
    "plt.minorticks_on()\n",
    "#we can set aspect ratio for the figure\n",
    "ratio = 0.7\n",
    "x_left, x_right = ax.get_xlim()\n",
    "y_low, y_high = ax.get_ylim()\n",
    "ax.set_aspect(abs((x_right-x_left)/(y_low-y_high))*ratio)\n",
    "plt.savefig(\"mtcars.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "boW5_x6hhddd"
   },
   "outputs": [],
   "source": [
    "x_range = np.linspace(ax.get_xlim()[0],ax.get_xlim()[1],100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_wN-OfYsD64C"
   },
   "outputs": [],
   "source": [
    "x = cars[\"wt\"].values\n",
    "y = cars[\"mpg\"].values\n",
    "lm = linear_model.LinearRegression()\n",
    "model = lm.fit(x.reshape(-1,1),y)\n",
    "xhat = np.array([1.1,5.9]).reshape(-1,1)\n",
    "yhat = lm.predict(xhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 474
    },
    "id": "W9OuQOxZcKfg",
    "outputId": "f06f3a26-6832-46ef-c948-432572688274"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "plt.plot(xhat, yhat, '-',color='red',lw=2)\n",
    "plt.scatter(cars[\"wt\"],cars[\"mpg\"],color='deepskyblue',ec='k',s=30,alpha=0.7)\n",
    "plt.xlim(1,6)\n",
    "plt.ylim(5,40)\n",
    "plt.xlabel('Weight',fontsize=18)\n",
    "plt.ylabel('Miles Per Gallon',fontsize=18)\n",
    "ax.grid()\n",
    "ax.grid(which='major', color='#DDDDDD', linewidth=0.8)\n",
    "ax.grid(which='minor', color='#EEEEEE', linestyle=':', linewidth=0.5)\n",
    "ax.set_axisbelow(True)\n",
    "plt.minorticks_on()\n",
    "plt.savefig(\"mtcars_line.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9BB4Jla9rJsx"
   },
   "outputs": [],
   "source": [
    "#Defining the bell shaped kernel function - used for plotting later on\n",
    "def kernel_function(xi,x0,tau= .005):\n",
    "    return np.exp( - (xi - x0)**2/(2*tau))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3Vqab2jmrdZn"
   },
   "outputs": [],
   "source": [
    "def weights_matrix(x,tau):\n",
    "  n = len(x)\n",
    "  return np.array([np.exp(- (x - x[i])**2/(2*tau)) for i in range(n)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d9AUt8fRrvYm"
   },
   "outputs": [],
   "source": [
    "w = weights_matrix(x,0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mf3ovR3rjdwQ",
    "outputId": "b13b880c-a24f-40c5-a282-35b3e11ce50a"
   },
   "outputs": [],
   "source": [
    "w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "Ksc6d2eVAAGp"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "def lowess_bell_shape_kern1(x, y, tau = .005):\n",
    "    \"\"\"lowess_bell_shape_kern(x, y, tau = .005) -> the estimate of y denoted \"yest\"\n",
    "    Locally weighted regression: fits a nonparametric regression curve to a scatterplot.\n",
    "    The arrays x and y contain an equal number of elements; each pair\n",
    "    (x[i], y[i]) defines a data point in the scatterplot. The function returns\n",
    "    the estimated (smooth) values of y.\n",
    "    The kernel function is the bell shaped function with parameter tau. Larger tau will result in a\n",
    "    smoother curve.\n",
    "    \"\"\"\n",
    "    n = len(x)\n",
    "    yest = np.zeros(n)\n",
    "\n",
    "    #Initializing all weights from the bell shape kernel function\n",
    "    # here w is an nxn matrix\n",
    "    w = weights_matrix(x,tau)\n",
    "\n",
    "    #Looping through all x-points\n",
    "    for i in range(n):\n",
    "        weights = w[:, i]\n",
    "        b = np.array([np.sum(weights * y), np.sum(weights * y * x)])\n",
    "        A = np.array([[np.sum(weights), np.sum(weights * x)],\n",
    "                    [np.sum(weights * x), np.sum(weights * x * x)]])\n",
    "        theta = linalg.solve(A, b)\n",
    "        yest[i] = theta[0] + theta[1] * x[i]\n",
    "\n",
    "    return yest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-YWtpBvPXajg"
   },
   "outputs": [],
   "source": [
    "def lowess_bell_shape_kern(x, y, tau = .005):\n",
    "    \"\"\"lowess_bell_shape_kern(x, y, tau = .005) -> the estimate of y denoted \"yest\"\n",
    "    Locally weighted regression: fits a nonparametric regression curve to a scatterplot.\n",
    "    The arrays x and y contain an equal number of elements; each pair\n",
    "    (x[i], y[i]) defines a data point in the scatterplot. The function returns\n",
    "    the estimated (smooth) values of y.\n",
    "    The kernel function is the bell shaped function with parameter tau. Larger tau will result in a\n",
    "    smoother curve.\n",
    "    \"\"\"\n",
    "    n = len(x)\n",
    "    yest = np.zeros(n)\n",
    "\n",
    "    #Initializing all weights from the bell shape kernel function\n",
    "    # here w is an nxn matrix\n",
    "    w = weights_matrix(x,tau)\n",
    "\n",
    "    #Looping through all x-points\n",
    "    for i in range(n):\n",
    "        weights = w[:, i]\n",
    "        lm.fit(np.diag(w[:,i]).dot(x.reshape(-1,1)),np.diag(w[:,i]).dot(y.reshape(-1,1)))\n",
    "        yest[i] = lm.predict(x[i].reshape(-1,1))\n",
    "\n",
    "    return yest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hqCp6wgcYGSu"
   },
   "outputs": [],
   "source": [
    "yhat = lowess_bell_shape_kern(x,y, tau= .03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 555
    },
    "id": "1wQdTrzPY-W0",
    "outputId": "66c8037b-468f-445e-b1a6-38de1a2df531"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "plt.plot(x[np.argsort(x)], yhat[np.argsort(x)], '-',color='red',lw=2)\n",
    "plt.scatter(cars[\"wt\"],cars[\"mpg\"],color='deepskyblue',ec='k',s=30,alpha=0.7)\n",
    "plt.xlim(1,6)\n",
    "plt.ylim(5,40)\n",
    "plt.xlabel('Weight',fontsize=18)\n",
    "plt.ylabel('Miles Per Gallon',fontsize=18)\n",
    "ax.grid()\n",
    "ax.grid(which='major', color='#DDDDDD', linewidth=0.8)\n",
    "ax.grid(which='minor', color='#EEEEEE', linestyle=':', linewidth=0.5)\n",
    "ax.set_axisbelow(True)\n",
    "plt.minorticks_on()\n",
    "plt.savefig(\"mtcars_line.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LVcJ49H3ZHX5"
   },
   "source": [
    "Interpretation: we expect to see on average an 5.34mpg drop if the weight of the car increases by 1 ton."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2PFDM8geJJwA"
   },
   "source": [
    "## Loess from Statsmodels Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8yIoAsOOJt5P"
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import scipy.stats as stats\n",
    "lowess = sm.nonparametric.lowess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p5htZNmUJseW"
   },
   "outputs": [],
   "source": [
    "# this is just an example with a simulated nonlinear relationship such as a sine wave\n",
    "x = np.random.uniform(low = -2*np.pi, high = 2*np.pi, size=500)\n",
    "x = np.sort(x)\n",
    "y = np.sin(x) + 0.5*np.random.normal(size=len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8vCuKe8OdniO"
   },
   "outputs": [],
   "source": [
    "# we can apply our function defined earlier\n",
    "yhat1 = lowess_bell_shape_kern(x,y,tau=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "adZsgnbMdfA2"
   },
   "outputs": [],
   "source": [
    "yhat2 = lowess(y, x, frac= 1/5, return_sorted = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 536
    },
    "id": "i6nmcat8KYV-",
    "outputId": "754c0f64-30d8-4fed-f0be-03f458d590ad"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "plt.scatter(x,y)\n",
    "plt.plot(x[np.argsort(x)],yhat1[np.argsort(x)],lw=2,color='red',label='loess bell shape kernel')\n",
    "plt.plot(x[np.argsort(x)],yhat2[np.argsort(x)],lw=2,color='green',label='loess from statsmodels')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BpBd0reguN28",
    "outputId": "c8b7f3e2-b4ac-4eaf-d88d-2da97e4951f3"
   },
   "outputs": [],
   "source": [
    "mse(yhat1,y), mse(yhat2,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tqhGN4Gztt4z"
   },
   "source": [
    "## Use of Different Kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qASL2X7XgSyH"
   },
   "outputs": [],
   "source": [
    "lm = linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RRzqfPIJhg__"
   },
   "outputs": [],
   "source": [
    "kernel = tricubic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3JlgLDjfgSrv"
   },
   "outputs": [],
   "source": [
    "def kernel_function(xi,x0,kern, tau):\n",
    "    return kern((xi - x0)/(2*tau))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mwzLyr8ZgSum"
   },
   "outputs": [],
   "source": [
    "def weights_matrix(x,kern,tau):\n",
    "  n = len(x)\n",
    "  return np.array([kernel_function(x,x[i],kern,tau) for i in range(n)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oQ_neKuQjrAk"
   },
   "outputs": [],
   "source": [
    "n = len(x)\n",
    "w = weights_matrix(x,kernel,0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w_aGPDrCtzn4"
   },
   "outputs": [],
   "source": [
    "def lowess(x, y, kern, tau=0.05):\n",
    "    # tau is called bandwidth K((x-x[i])/(2*tau))\n",
    "    # tau is a hyper-parameter\n",
    "    n = len(x)\n",
    "    yest = np.zeros(n)\n",
    "\n",
    "    #Initializing all weights from the bell shape kernel function\n",
    "    #Looping through all x-points\n",
    "\n",
    "    w = weights_matrix(x,kern,tau)\n",
    "\n",
    "    #Looping through all x-points\n",
    "    for i in range(n):\n",
    "        weights = w[:, i]\n",
    "        lm.fit(np.diag(w[:,i]).dot(x.reshape(-1,1)),np.diag(w[:,i]).dot(y.reshape(-1,1)))\n",
    "        yest[i] = lm.predict(x[i].reshape(-1,1))\n",
    "\n",
    "    return yest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GAcc1QvzoWGQ"
   },
   "source": [
    "### Reference\n",
    "https://xavierbourretsicotte.github.io/loess.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0v6JRc-Kwm_M"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GFcxmTTxtzqt"
   },
   "outputs": [],
   "source": [
    "yest = lowess(x,y,kernel,0.04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Hm7J7AJtzs1",
    "outputId": "945105ac-b418-42ac-b841-adf14861a580"
   },
   "outputs": [],
   "source": [
    "yest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ufDdEg-UwvOi"
   },
   "source": [
    "## Another Implementation - A Theory-based Robust Approach\n",
    "\n",
    "### Gramfort's Approach\n",
    "\n",
    "The idea is based on the following references:\n",
    "\n",
    "- William S. Cleveland: \"Robust locally weighted regression and smoothing\n",
    "scatterplots\", Journal of the American Statistical Association, December 1979,\n",
    "volume 74, number 368, pp. 829-836.\n",
    "\n",
    "- William S. Cleveland and Susan J. Devlin: \"Locally weighted regression: An\n",
    "approach to regression analysis by local fitting\", Journal of the American\n",
    "Statistical Association, September 1988, volume 83, number 403, pp. 596-610.\n",
    "\n",
    "The main idea is to perform a local linear regression in a neighborhood of k observations close by and then apply an iteration to rescale the weights based on the residuals; this step is argued to yield a more robust model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B21_4_YitzvT"
   },
   "outputs": [],
   "source": [
    "# approach by Alex Gramfort https://gist.github.com/agramfort\n",
    "\n",
    "def lowess_ag(x, y, f=2. / 3., iter=3):\n",
    "    \"\"\"lowess(x, y, f=2./3., iter=3) -> yest\n",
    "    Lowess smoother: Robust locally weighted regression.\n",
    "    The lowess function fits a nonparametric regression curve to a scatterplot.\n",
    "    The arrays x and y contain an equal number of elements; each pair\n",
    "    (x[i], y[i]) defines a data point in the scatterplot. The function returns\n",
    "    the estimated (smooth) values of y.\n",
    "    The smoothing span is given by f. A larger value for f will result in a\n",
    "    smoother curve. The number of robustifying iterations is given by iter. The\n",
    "    function will run faster with a smaller number of iterations.\n",
    "    \"\"\"\n",
    "    n = len(x)\n",
    "    r = int(np.ceil(f * n))\n",
    "    h = [np.sort(np.abs(x - x[i]))[r] for i in range(n)]\n",
    "    w = np.clip(np.abs((x[:, None] - x[None, :]) / h), 0.0, 1.0)\n",
    "    w = (1 - w ** 3) ** 3\n",
    "    yest = np.zeros(n)\n",
    "    delta = np.ones(n)\n",
    "    for iteration in range(iter):\n",
    "        for i in range(n):\n",
    "            weights = delta * w[:, i]\n",
    "            b = np.array([np.sum(weights * y), np.sum(weights * y * x)])\n",
    "            A = np.array([[np.sum(weights), np.sum(weights * x)],\n",
    "                          [np.sum(weights * x), np.sum(weights * x * x)]])\n",
    "            beta = linalg.solve(A, b)\n",
    "            yest[i] = beta[0] + beta[1] * x[i]\n",
    "\n",
    "        residuals = y - yest\n",
    "        s = np.median(np.abs(residuals))\n",
    "        delta = np.clip(residuals / (6.0 * s), -1, 1)\n",
    "        delta = (1 - delta ** 2) ** 2\n",
    "\n",
    "    return yest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xz_LiMZUtzxh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xucB_ottsWZb"
   },
   "source": [
    "## Applications with Simulated Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yh3vVuH6symw"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 649
    },
    "id": "Q7Qu7yIMZWTU",
    "outputId": "a8b01603-8303-4973-8f71-9bf25e926cc4"
   },
   "outputs": [],
   "source": [
    "#Initializing noisy non linear data\n",
    "x = np.linspace(0,1,100)\n",
    "noise = np.random.normal(loc = 0, scale = .25, size = 100)\n",
    "y = np.sin(x * 1.5 * np.pi )\n",
    "y_noise = y + noise\n",
    "\n",
    "#Plotting the noisy data and the kernell at around x = 0.2\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(x,y,color = 'darkblue', label = 'f(x)')\n",
    "plt.scatter(x,y_noise, facecolors = 'none', edgecolor = 'darkblue', label = 'f(x) + noise')\n",
    "plt.fill(x[:40],kernel_function(x[:40],0.2,kernel,.05), color = 'lime', alpha = .5, label = 'Kernel')\n",
    "plt.legend()\n",
    "plt.title('Noisy sine function and bell shaped kernel at x=.2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uzg8zq69xhyh"
   },
   "outputs": [],
   "source": [
    "# application of the two flavors of Loess\n",
    "f = 0.25\n",
    "yest1 = lowess_ag(x, y, f=f, iter=3)\n",
    "yest2 = lowess(x,y,kernel,0.04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 649
    },
    "id": "3tzqOva-x5bD",
    "outputId": "12d8d40d-aec4-41ac-b676-1be07c0129c4"
   },
   "outputs": [],
   "source": [
    "# display what we got\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(x,y,color = 'darkblue', label = 'sin()')\n",
    "plt.scatter(x,y_noise, facecolors = 'none', edgecolor = 'darkblue', label = 'sin() + noise')\n",
    "plt.fill(x[:40],kernel_function(x[:40],0.2,kernel,.005), color = 'lime', alpha = .5, label = 'Given kernel')\n",
    "plt.plot(x,yest1,color = 'orange', label = 'Loess: A. Gramfort')\n",
    "plt.plot(x,yest2,color = 'red', label = 'Loess with given kernel')\n",
    "plt.legend()\n",
    "plt.title('Sine with noise: Loess regression and a given kernel')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J057P7OfyLv7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4JepvRCkmZnC"
   },
   "source": [
    "## Another example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3S0aVzNCbny1"
   },
   "outputs": [],
   "source": [
    "#Initializing noisy non linear data\n",
    "x = np.linspace(0,4,400)\n",
    "noise = np.random.normal(loc = 0, scale = .8, size = 400)\n",
    "y = np.sin(x**2 * 1.5 * np.pi )\n",
    "y_noise = y + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KYEUTzYXbpjK"
   },
   "outputs": [],
   "source": [
    "xlr = x.reshape(-1,1)\n",
    "y_noiselr = y_noise.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H848VGCKcLY2"
   },
   "outputs": [],
   "source": [
    "# we want to compare with linear regression\n",
    "yhat_lr = lr.predict(xlr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 630
    },
    "id": "_XMlDmAbLbKd",
    "outputId": "f40ef6ec-f6b8-4397-98c5-f249e9a3fe91"
   },
   "outputs": [],
   "source": [
    "#Plotting the noisy data and the kernell at around x = 0.2\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(x,y,color = 'darkblue', label = 'f(x)')\n",
    "plt.plot(xlr,yhat_lr,color='red',lw=2,label = 'Weak Learner')\n",
    "plt.scatter(x,y_noise, facecolors = 'none', edgecolor = 'darkblue', label = 'f(x) + noise')\n",
    "plt.fill(x[:40],kernel_function(x[:40],0.2,tricubic,.09), color = 'lime', alpha = .5, label = 'Kernel')\n",
    "plt.legend()\n",
    "plt.title('Noisy sine function and weak learner')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EJMDr15JLc8r"
   },
   "outputs": [],
   "source": [
    "## here is where we make predictions with our kernel\n",
    "tau = 0.009\n",
    "\n",
    "yhat_kern = lowess(x,y,tricubic,tau)\n",
    "\n",
    "f = 0.02\n",
    "yest = lowess_ag(x, y, f=f, iter=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 721
    },
    "id": "F0yzG5ZGOTHF",
    "outputId": "6bb49102-1932-4d91-83fc-c7f1ddf731db"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,7))\n",
    "plt.plot(x,y,color = 'darkblue', label = 'sin()',lw=2)\n",
    "plt.scatter(x,y_noise, facecolors = 'none', edgecolor = 'darkblue', label = 'sin() + noise')\n",
    "plt.fill(x[:40],kernel_function(x[:40],0.2,tricubic,0.1), color = 'lime', alpha = .5, label = 'Given Kernel')\n",
    "plt.plot(x,yest,color = 'orange', label = 'Loess: A. Gramfort')\n",
    "plt.plot(x,yhat_kern,color = 'red', label = 'Loess: Given kernel')\n",
    "plt.legend()\n",
    "plt.title('Sine with noise: Loess regression and kernel')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ViB5wGuJzYLp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vODoxRgnWqgk"
   },
   "source": [
    "##<font face='menlo' size=6pt> Applications with Real Data </font>\n",
    "\n",
    "First let's make a more usable function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NWl7TNq-PBE8"
   },
   "outputs": [],
   "source": [
    "def lowess_reg(x, y, xnew, kern, tau):\n",
    "    # tau is called bandwidth K((x-x[i])/(2*tau))\n",
    "    # IMPORTANT: we expect x to the sorted increasingly\n",
    "    n = len(x)\n",
    "    yest = np.zeros(n)\n",
    "\n",
    "    #Initializing all weights from the bell shape kernel function\n",
    "    w = np.array([kern((x - x[i])/(2*tau)) for i in range(n)])\n",
    "\n",
    "    #Looping through all x-points\n",
    "    for i in range(n):\n",
    "        weights = w[:, i]\n",
    "        b = np.array([np.sum(weights * y), np.sum(weights * y * x)])\n",
    "        A = np.array([[np.sum(weights), np.sum(weights * x)],\n",
    "                    [np.sum(weights * x), np.sum(weights * x * x)]])\n",
    "        #theta = linalg.solve(A, b) # A*theta = b\n",
    "        theta, res, rnk, s = linalg.lstsq(A, b)\n",
    "        yest[i] = theta[0] + theta[1] * x[i]\n",
    "    f = interp1d(x, yest,fill_value='extrapolate')\n",
    "    return f(xnew)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yz7YqwRddVDE"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('drive/MyDrive/Data Sets/cars.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "_TvfAvBI9S_k",
    "outputId": "dd2052ca-539d-464d-a17c-fd033ba6abee"
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V-bdrW_79j-i"
   },
   "outputs": [],
   "source": [
    "x = data['WGT'].values\n",
    "y = data['MPG'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mkhXecNLbJwx",
    "outputId": "3b6278e1-0652-46d5-fc9a-0ff811fda4af"
   },
   "outputs": [],
   "source": [
    "lowess_reg(x,y,3200,tricubic,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "Iwa64U6EgXIf",
    "outputId": "7073cea3-a4cb-4564-d579-20c8921948dd"
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "daoBuXV7gX5i",
    "outputId": "4d36b93f-6fab-41b1-b086-521bd31c78fd"
   },
   "outputs": [],
   "source": [
    "plt.scatter(data['WGT'],data['MPG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j1vuxbc7iUkt"
   },
   "outputs": [],
   "source": [
    "xnew = np.arange(1500,5500,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YxbrmH1bisY7"
   },
   "outputs": [],
   "source": [
    "yhat = lowess_reg(x,y,xnew,tricubic,150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "80qrWSi6itaj",
    "outputId": "ed436e43-768d-45c6-ba3b-e75536ee6b65"
   },
   "outputs": [],
   "source": [
    "plt.scatter(data['WGT'],data['MPG'])\n",
    "plt.plot(xnew,yhat,color='red',lw=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P6xVF7mbz94J"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9jumnX3LcASV"
   },
   "source": [
    "## Applications with Train & Test Data\n",
    "\n",
    "Big Idea: we need to acommodate new data points in a test set. We can only get weights from the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bNxmczIPz-VO"
   },
   "outputs": [],
   "source": [
    "def kernel_function(xi,x0,kern, tau):\n",
    "    return kern((xi - x0)/(2*tau))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KcC_X7zdz-VO"
   },
   "outputs": [],
   "source": [
    "def weights_matrix(x,x_new,kern,tau):\n",
    "  if np.isscalar(x_new):\n",
    "    return kernel_function(x,x_new,kern,tau)\n",
    "  else:\n",
    "    n = len(x_new)\n",
    "    return np.array([kernel_function(x,x_new[i],kern,tau) for i in range(n)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bvxg-lZye0kb"
   },
   "outputs": [],
   "source": [
    "def lowess(x, y,x_new, kern, tau=0.05):\n",
    "    # tau is called bandwidth K((x-x[i])/(2*tau))\n",
    "    # tau is a hyper-parameter\n",
    "    w = weights_matrix(x,x_new,kern,tau)\n",
    "    if np.isscalar(x_new):\n",
    "      lm.fit(np.diag(w).dot(x.reshape(-1,1)),np.diag(w).dot(y.reshape(-1,1)))\n",
    "      yest = lm.predict([[x_new]])[0][0]\n",
    "    else:\n",
    "      n = len(x_new)\n",
    "      yest = np.zeros(n)\n",
    "      #Looping through all x-points\n",
    "      for i in range(n):\n",
    "        lm.fit(np.diag(w[i,:]).dot(x.reshape(-1,1)),np.diag(w[i,:]).dot(y.reshape(-1,1)))\n",
    "        yest[i] = lm.predict(x_new[i].reshape(-1,1))\n",
    "\n",
    "    return yest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ns02xUQQx1UB"
   },
   "source": [
    "## Scikit-Learn Compliant Functions\n",
    "\n",
    "Main Idea: we want to define a model regressor that can be used as model.fit/model.predict, and that also allows sklearn GridSearchCV for tuning hyperparameters.\n",
    "\n",
    "*Self* represents the instance of the class. By using the “self”  we can access the attributes and methods of the class in python. It binds the attributes with the given arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wd5BIX08z-DR"
   },
   "outputs": [],
   "source": [
    "class Lowess:\n",
    "    def __init__(self, kernel = Gaussian, tau=0.05):\n",
    "        self.kernel = kernel\n",
    "        self.tau = tau\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        kernel = self.kernel\n",
    "        tau = self.tau\n",
    "        # w = weights_matrix(x,x,kernel,tau)\n",
    "        # if np.isscalar(x):\n",
    "        #   lm.fit(np.diag(w).dot(x.reshape(-1,1)),np.diag(w).dot(y.reshape(-1,1)))\n",
    "        #   yest = lm.predict([[x]])[0][0]\n",
    "        # else:\n",
    "        #   n = len(x)\n",
    "        #   yest = np.zeros(n)\n",
    "        #   #Looping through all x-points\n",
    "        #   for i in range(n):\n",
    "        #     lm.fit(np.diag(w[i,:]).dot(x.reshape(-1,1)),np.diag(w[i,:]).dot(y.reshape(-1,1)))\n",
    "        #     yest[i] = lm.predict(x[i].reshape(-1,1))\n",
    "        self.xtrain_ = x\n",
    "        self.yhat_ = y\n",
    "\n",
    "    def predict(self, x_new):\n",
    "        check_is_fitted(self)\n",
    "        x = self.xtrain_\n",
    "        y = self.yhat_\n",
    "\n",
    "        w = weights_matrix(x,x_new,self.kernel,self.tau)\n",
    "\n",
    "        if np.isscalar(x_new):\n",
    "          lm.fit(np.diag(w).dot(x.reshape(-1,1)),np.diag(w).dot(y.reshape(-1,1)))\n",
    "          yest = lm.predict([[x_new]])[0][0]\n",
    "        else:\n",
    "          n = len(x_new)\n",
    "          yest_test = np.zeros(n)\n",
    "          #Looping through all x-points\n",
    "          for i in range(n):\n",
    "            lm.fit(np.diag(w[i,:]).dot(x.reshape(-1,1)),np.diag(w[i,:]).dot(y.reshape(-1,1)))\n",
    "            yest_test[i] = lm.predict(x_new[i].reshape(-1,1))\n",
    "        return yest_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2ZoAsZTo0Wa_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4mognSkYitbE"
   },
   "source": [
    "## Testing on Simulated Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bah1LEv1iwzu"
   },
   "outputs": [],
   "source": [
    "#Initializing noisy non linear data\n",
    "x = np.linspace(0,4,401)\n",
    "noise = np.random.normal(loc = 0, scale = .2, size = len(x))\n",
    "y = np.sin(x**2 * 1.5 * np.pi )\n",
    "ynoisy = y + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8BNqG46UiybE"
   },
   "outputs": [],
   "source": [
    "xtrain, xtest, ytrain, ytest = tts(x,ynoisy,test_size=0.2,shuffle=True,random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "40VX8w_5qh0_",
    "outputId": "40f9614d-a8b9-4ca0-ded3-e9a188403e93"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# test the regressor\n",
    "model = Lowess(kernel=Epanechnikov,tau=0.02)\n",
    "model.fit(xtrain,ytrain)\n",
    "mse(model.predict(xtest),ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KVFFoeY7O5Yr",
    "outputId": "073cd8a8-1db1-4a78-b16b-8243a22f1295"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "model_rf = RandomForestRegressor(n_estimators=200, max_depth=10)\n",
    "model_rf.fit(xtrain.reshape(-1,1),ytrain)\n",
    "mse(model_rf.predict(xtest.reshape(-1,1)),ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 623
    },
    "id": "fx0f65r0iyXa",
    "outputId": "e760734a-76ac-4c5f-87d1-74c5e048bff9"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(xtest,ytest,ec='blue',alpha=0.5)\n",
    "plt.plot(xtest[np.argsort(xtest)],model.predict(xtest[np.argsort(xtest)]),color='red',lw=2,label='Kernel Regression')\n",
    "plt.plot(xtest[np.argsort(xtest)],model_rf.predict(xtest[np.argsort(xtest)].reshape(-1,1)),color='orange',lw=2,label='Random Forest')\n",
    "plt.plot(x,y,color='green',lw=2,label='Truth')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
