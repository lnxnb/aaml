{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "pwyjEt2KDbOs"
   },
   "outputs": [],
   "source": [
    "# this block of code imports graphical libraries for plotting graphs with high resolution\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi'] = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "MngkC29k1xTd"
   },
   "outputs": [],
   "source": [
    "# Libraries of functions need to be imported\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from scipy.spatial import Delaunay\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split as tts, KFold, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from scipy import linalg\n",
    "from scipy.interpolate import interp1d, LinearNDInterpolator, NearestNDInterpolator\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# the following line(s) are necessary if you want to make SKlearn compliant functions\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pVJN1dFl1FH1"
   },
   "outputs": [],
   "source": [
    "# Gaussian Kernel\n",
    "def Gaussian(x):\n",
    "  return np.where(np.abs(x)>4,0,1/(np.sqrt(2*np.pi))*np.exp(-1/2*x**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2rh_RP12cYwK"
   },
   "outputs": [],
   "source": [
    "# this is the correct vectorized version\n",
    "def tricubic(x):\n",
    "  return np.where(np.abs(x)>1,0,(1-np.abs(x)**3)**3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4TtZzxpteCO0"
   },
   "outputs": [],
   "source": [
    "# Epanechnikov Kernel\n",
    "def Epanechnikov(x):\n",
    "  return np.where(np.abs(x)>1,0,3/4*(1-np.abs(x)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lZ1rmjMfywSx"
   },
   "outputs": [],
   "source": [
    "# Quartic Kernel\n",
    "def Quartic(x):\n",
    "  return np.where(np.abs(x)>1,0,15/16*(1-np.abs(x)**2)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BSF03-Kv4bhU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aHOdI-g04b9t"
   },
   "outputs": [],
   "source": [
    "# this block of code imports graphical libraries for plotting graphs with high resolution\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi'] = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2nVqUUPG4b9u"
   },
   "outputs": [],
   "source": [
    "# Libraries of functions need to be imported\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from scipy import linalg\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "# the following line(s) are necessary if you want to make SKlearn compliant functions\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gfWhN-kR4b9u"
   },
   "outputs": [],
   "source": [
    "# Gaussian Kernel\n",
    "def Gaussian(x):\n",
    "  return np.where(np.abs(x)>4,0,1/(np.sqrt(2*np.pi))*np.exp(-1/2*x**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qN3Di4Vz4b9u"
   },
   "outputs": [],
   "source": [
    "# this is the correct vectorized version\n",
    "def tricubic(x):\n",
    "  return np.where(np.abs(x)>1,0,(1-np.abs(x)**3)**3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WeOashtG4b9u"
   },
   "outputs": [],
   "source": [
    "# Epanechnikov Kernel\n",
    "def Epanechnikov(x):\n",
    "  return np.where(np.abs(x)>1,0,3/4*(1-np.abs(x)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7_sHVlQE4b9v"
   },
   "outputs": [],
   "source": [
    "# Quartic Kernel\n",
    "def Quartic(x):\n",
    "  return np.where(np.abs(x)>1,0,15/16*(1-np.abs(x)**2)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9jumnX3LcASV"
   },
   "source": [
    "## Applications with Train & Test Data\n",
    "\n",
    "Big Idea: we need to acommodate new data points in a test set. We can only get weights from the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "XLxEL2wETcJT"
   },
   "outputs": [],
   "source": [
    "def dist(u,v):\n",
    "  if len(v.shape)==1:\n",
    "    v = v.reshape(1,-1)\n",
    "  d = np.array([np.sqrt(np.sum((u-v[i])**2,axis=1)) for i in range(len(v))])\n",
    "  return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "bNxmczIPz-VO"
   },
   "outputs": [],
   "source": [
    "def kernel_function(xi,x0,kern, tau):\n",
    "    return kern(dist(xi,x0)/(2*tau))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "KcC_X7zdz-VO"
   },
   "outputs": [],
   "source": [
    "def weights_matrix(x,x_new,kern,tau):\n",
    "  if np.isscalar(x_new):\n",
    "    return kernel_function(x,x_new,kern,tau)\n",
    "  else:\n",
    "    n = len(x_new)\n",
    "    return np.array([kernel_function(x,x_new[i],kern,tau) for i in range(n)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "Qo0-u8rnNcPg"
   },
   "outputs": [],
   "source": [
    "lm = linear_model.LinearRegression() # or, more creatively, we could use a etc. regularized linear model such as Ridge, Lasso, ElasticNet,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ns02xUQQx1UB"
   },
   "source": [
    "## Scikit-Learn Compliant Functions\n",
    "\n",
    "Main Idea: we want to define a model regressor that can be used as model.fit/model.predict, and that also allows sklearn GridSearchCV for tuning hyperparameters.\n",
    "\n",
    "*Self* represents the instance of the class. By using the “self”  we can access the attributes and methods of the class in python. It binds the attributes with the given arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HRd6tTE_4xuh"
   },
   "outputs": [],
   "source": [
    "# get some real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "NRoXCJCRsIVH"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('drive/MyDrive/Data Sets/cars.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "prf6xlfatFqx"
   },
   "outputs": [],
   "source": [
    "x = data.loc[:,'CYL':'WGT'].values\n",
    "y = data['MPG'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "QZxxke5_BtrL"
   },
   "outputs": [],
   "source": [
    "scale = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TnpMRqICUUD6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "Osoez3m9XmV-"
   },
   "outputs": [],
   "source": [
    "def lw_ag_md(x, y, xnew,f=2/3,iter=3, intercept=True):\n",
    "\n",
    "  n = len(x)\n",
    "  r = int(np.ceil(f * n))\n",
    "  yest = np.zeros(n)\n",
    "\n",
    "  if len(y.shape)==1: # here we make column vectors\n",
    "    y = y.reshape(-1,1)\n",
    "\n",
    "  if len(x.shape)==1:\n",
    "    x = x.reshape(-1,1)\n",
    "\n",
    "  if intercept:\n",
    "    x1 = np.column_stack([np.ones((len(x),1)),x])\n",
    "  else:\n",
    "    x1 = x\n",
    "\n",
    "  h = [np.sort(np.sqrt(np.sum((x-x[i])**2,axis=1)))[r] for i in range(n)]\n",
    "  # dist(x,x) is always symmetric\n",
    "  w = np.clip(dist(x,x) / h, 0.0, 1.0)\n",
    "  w = (1 - w ** 3) ** 3\n",
    "\n",
    "  #Looping through all X-points\n",
    "  delta = np.ones(n)\n",
    "  for iteration in range(iter):\n",
    "    for i in range(n):\n",
    "      W = np.diag(delta).dot(np.diag(w[i,:]))\n",
    "      # when we multiply two diagional matrices we get also a diagonal matrix\n",
    "      b = np.transpose(x1).dot(W).dot(y)\n",
    "      A = np.transpose(x1).dot(W).dot(x1)\n",
    "      ##\n",
    "      A = A + 0.0001*np.eye(x1.shape[1]) # if we want L2 regularization\n",
    "      beta = linalg.solve(A, b)\n",
    "      #beta, res, rnk, s = linalg.lstsq(A, b)\n",
    "      yest[i] = np.dot(x1[i],beta)\n",
    "\n",
    "    residuals = y.ravel() - yest\n",
    "    s = np.median(np.abs(residuals))\n",
    "\n",
    "    delta = np.clip(residuals / (6.0 * s), -1, 1)\n",
    "\n",
    "    delta = (1 - delta ** 2) ** 2\n",
    "\n",
    "\n",
    "  if x.shape[1]==1:\n",
    "    f = interp1d(x.flatten(),yest,fill_value='extrapolate')\n",
    "    output = f(xnew)\n",
    "  else:\n",
    "    output = np.zeros(len(xnew))\n",
    "    for i in range(len(xnew)):\n",
    "      ind = np.argsort(np.sqrt(np.sum((x-xnew[i])**2,axis=1)))[:r]\n",
    "      pca = PCA(n_components=2)\n",
    "      x_pca = pca.fit_transform(x[ind])\n",
    "      tri = Delaunay(x_pca,qhull_options='QJ')\n",
    "      f = LinearNDInterpolator(tri,yest[ind])\n",
    "      output[i] = f(pca.transform(xnew[i].reshape(1,-1))) # the output may have NaN's where the data points from xnew are outside the convex hull of X\n",
    "  if sum(np.isnan(output))>0:\n",
    "    g = NearestNDInterpolator(x,y.ravel())\n",
    "    # output[np.isnan(output)] = g(X[np.isnan(output)])\n",
    "    output[np.isnan(output)] = g(xnew[np.isnan(output)])\n",
    "  return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "6r_cVSa6dEPM"
   },
   "outputs": [],
   "source": [
    "class Lowess_AG_MD:\n",
    "    def __init__(self, f = 1/10, iter = 3,intercept=True):\n",
    "        self.f = f\n",
    "        self.iter = iter\n",
    "        self.intercept = intercept\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        f = self.f\n",
    "        iter = self.iter\n",
    "        self.xtrain_ = x\n",
    "        self.yhat_ = y\n",
    "\n",
    "    def predict(self, x_new):\n",
    "        check_is_fitted(self)\n",
    "        x = self.xtrain_\n",
    "        y = self.yhat_\n",
    "        f = self.f\n",
    "        iter = self.iter\n",
    "        intercept = self.intercept\n",
    "        return lw_ag_md(x, y, x_new, f, iter, intercept) # this is actually our defined function of Lowess\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "    # suppose this estimator has parameters \"f\", \"iter\" and \"intercept\"\n",
    "        return {\"f\": self.f, \"iter\": self.iter,\"intercept\":self.intercept}\n",
    "\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zBSpXHBh4x2j",
    "outputId": "939159f5-d7c7-4004-d5e7-6958a91bca64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Cross-validated Mean Squared Error for Locally Weighted Regression is : 16.530161925219694\n",
      "The Cross-validated Mean Squared Error for Random Forest is : 17.56419158565313\n"
     ]
    }
   ],
   "source": [
    "mse_lwr = []\n",
    "mse_rf = []\n",
    "kf = KFold(n_splits=10,shuffle=True,random_state=1234)\n",
    "model_rf = RandomForestRegressor(n_estimators=200,max_depth=7)\n",
    "model_lw = Lowess_AG_MD(f=1/3,iter=2,intercept=True)\n",
    "\n",
    "for idxtrain, idxtest in kf.split(x):\n",
    "  xtrain = x[idxtrain]\n",
    "  ytrain = y[idxtrain]\n",
    "  ytest = y[idxtest]\n",
    "  xtest = x[idxtest]\n",
    "  xtrain = scale.fit_transform(xtrain)\n",
    "  xtest = scale.transform(xtest)\n",
    "\n",
    "  model_lw.fit(xtrain,ytrain)\n",
    "  yhat_lw = model_lw.predict(xtest)\n",
    "\n",
    "  model_rf.fit(xtrain,ytrain)\n",
    "  yhat_rf = model_rf.predict(xtest)\n",
    "\n",
    "  mse_lwr.append(mse(ytest,yhat_lw))\n",
    "  mse_rf.append(mse(ytest,yhat_rf))\n",
    "print('The Cross-validated Mean Squared Error for Locally Weighted Regression is : '+str(np.mean(mse_lwr)))\n",
    "print('The Cross-validated Mean Squared Error for Random Forest is : '+str(np.mean(mse_rf)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JUX4mQ3YUUGq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oRngnjlxUUI-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OrzaPkc5UULZ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K-nsGmyLUUN7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1M71V0l-UUQl"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MnanZDW5UUS9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ORCUfdxTVy4J"
   },
   "source": [
    "## Exercise:\n",
    "\n",
    "Adjust the code below and make it work without errors. Compare the results with the previous ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "bvxg-lZye0kb"
   },
   "outputs": [],
   "source": [
    "def lowess(x, y,x_new, kern, tau=0.05):\n",
    "    # tau is called bandwidth K((x-x[i])/(2*tau))\n",
    "    # tau is a hyper-parameter\n",
    "    w = weights_matrix(x,x_new,kern,tau)\n",
    "    if np.isscalar(x_new):\n",
    "      lm.fit(np.diag(w).dot(x.reshape(-1,1)),np.diag(w).dot(y.reshape(-1,1)))\n",
    "      yest = lm.predict([[x_new]])[0][0]\n",
    "    else:\n",
    "      n = len(x_new)\n",
    "      yest = np.zeros(n)\n",
    "      #Looping through all x-points\n",
    "      for i in range(n):\n",
    "        lm.fit(np.diag(w[i,:]).dot(x.reshape(-1,1)),np.diag(w[i,:]).dot(y.reshape(-1,1)))\n",
    "        yest[i] = lm.predict(x_new[i].reshape(-1,1))\n",
    "\n",
    "    return yest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "wd5BIX08z-DR"
   },
   "outputs": [],
   "source": [
    "class Lowess:\n",
    "    def __init__(self, kernel = Gaussian, tau=0.05):\n",
    "        self.kernel = kernel\n",
    "        self.tau = tau\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        kernel = self.kernel\n",
    "        tau = self.tau\n",
    "        # w = weights_matrix(x,x,kernel,tau)\n",
    "        # if np.isscalar(x):\n",
    "        #   lm.fit(np.diag(w).dot(x.reshape(-1,1)),np.diag(w).dot(y.reshape(-1,1)))\n",
    "        #   yest = lm.predict([[x]])[0][0]\n",
    "        # else:\n",
    "        #   n = len(x)\n",
    "        #   yest = np.zeros(n)\n",
    "        #   #Looping through all x-points\n",
    "        #   for i in range(n):\n",
    "        #     lm.fit(np.diag(w[i,:]).dot(x.reshape(-1,1)),np.diag(w[i,:]).dot(y.reshape(-1,1)))\n",
    "        #     yest[i] = lm.predict(x[i].reshape(-1,1))\n",
    "        self.xtrain_ = x\n",
    "        self.yhat_ = y\n",
    "\n",
    "    def predict(self, x_new):\n",
    "        check_is_fitted(self)\n",
    "        x = self.xtrain_\n",
    "        y = self.yhat_\n",
    "\n",
    "        w = weights_matrix(x,x_new,self.kernel,self.tau)\n",
    "\n",
    "        if np.isscalar(x_new):\n",
    "          lm.fit(np.diag(w).dot(x.reshape(-1,1)),np.diag(w).dot(y.reshape(-1,1)))\n",
    "          yest = lm.predict([[x_new]])[0][0]\n",
    "        else:\n",
    "          n = len(x_new)\n",
    "          yest_test = np.zeros(n)\n",
    "          #Looping through all x-points\n",
    "          for i in range(n):\n",
    "            print(np.diag(w[i,:]).shape)\n",
    "            lm.fit(np.diag(w[i,:])@x,np.diag(w[i,:])@y)\n",
    "            yest_test[i] = lm.predict(x_new[i])\n",
    "        return yest_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sU7PLYpcUUWi"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-SBgRVlw4x60"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6_qF58dE4x97"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
