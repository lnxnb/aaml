{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8ef365f",
   "metadata": {},
   "source": [
    "# 1. (6 points) Create your class that implements the Gradient Boosting concept, based on the locally weighted regression method (Lowess class), and that allows a user-prescribed number of boosting steps. \n",
    "\n",
    "The class you develop should have all the mainstream useful options, including “fit,” “is_fitted”,  and “predict,” methods.  Show applications with real data for regression, 10-fold cross-validations and compare the effect of different scalers, such as the “StandardScaler”, “MinMaxScaler”, and the “QuantileScaler”.  In the case of the “Concrete” data set, determine a choice of hyperparameters that yield lower MSEs for your method when compared to the eXtream Gradient Boosting library.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "471bce96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import ceil\n",
    "from scipy import linalg\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.spatial import Delaunay\n",
    "from scipy.interpolate import interp1d, RegularGridInterpolator, griddata, LinearNDInterpolator, NearestNDInterpolator\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, QuantileTransformer\n",
    "from sklearn.model_selection import train_test_split as tts, KFold, GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn import linear_model\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "\n",
    "#Using kernels, distance, weight, and Lowess code from class\n",
    "\n",
    "# Gaussian Kernel\n",
    "def Gaussian(x):\n",
    "  return np.where(np.abs(x)>4,0,1/(np.sqrt(2*np.pi))*np.exp(-1/2*x**2))\n",
    "# this is the correct vectorized version\n",
    "def tricubic(x):\n",
    "  return np.where(np.abs(x)>1,0,(1-np.abs(x)**3)**3)\n",
    "# Epanechnikov Kernel\n",
    "def Epanechnikov(x):\n",
    "  return np.where(np.abs(x)>1,0,3/4*(1-np.abs(x)**2))\n",
    "# Quartic Kernel\n",
    "def Quartic(x):\n",
    "  return np.where(np.abs(x)>1,0,15/16*(1-np.abs(x)**2)**2)\n",
    "\n",
    "def weight_function(u,v,kern=Epanechnikov,tau=0.1):\n",
    "    return kern(dist(u,v)/(2*tau))\n",
    "\n",
    "def dist(u,v):\n",
    "  D = []\n",
    "  if len(v.shape)==1:\n",
    "    v = v.reshape(1,-1)\n",
    "  # we would like all the pairwise combinations if u and v are matrices\n",
    "  # we could avoid two for loops if we consider broadcasting\n",
    "  for rowj in v:\n",
    "    D.append(np.sqrt(np.sum((u-rowj)**2,axis=1)))\n",
    "  return np.array(D).T\n",
    "\n",
    "def kernel_function(xi,x0,kern, tau):\n",
    "    return kern((xi - x0)/(2*tau))\n",
    "\n",
    "class Lowess:\n",
    "    def __init__(self, kernel = Gaussian, tau=0.05):\n",
    "        self.kernel = kernel\n",
    "        self.tau = tau\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        kernel = self.kernel\n",
    "        tau = self.tau\n",
    "        self.xtrain_ = x\n",
    "        self.yhat_ = y\n",
    "\n",
    "    def predict(self, x_new):\n",
    "        check_is_fitted(self)\n",
    "        x = self.xtrain_\n",
    "        y = self.yhat_\n",
    "        lm = linear_model.Ridge(alpha=0.001)\n",
    "        w = weight_function(x,x_new,self.kernel,self.tau)\n",
    "\n",
    "        if np.isscalar(x_new):\n",
    "          lm.fit(np.diag(w)@(x.reshape(-1,1)),np.diag(w)@(y.reshape(-1,1)))\n",
    "          yest = lm.predict([[x_new]])[0][0]\n",
    "        else:\n",
    "          n = len(x_new)\n",
    "          yest_test = np.zeros(n)\n",
    "          #Looping through all x-points\n",
    "          for i in range(n):\n",
    "            lm.fit(np.diag(w[:,i])@x,np.diag(w[:,i])@y)\n",
    "            yest_test[i] = lm.predict([x_new[i]])\n",
    "        return yest_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "ce50019f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For tau of 0.25 and boost iterations of 2 and n scaling quantiles of 70 for QuantileTransformer scaling\n",
      "Gradboost MSE is: 37.591693083352524\n",
      "XGBoost MSE is: 39.099963288898365\n"
     ]
    }
   ],
   "source": [
    "#XGBoost setup for comparison:\n",
    "import xgboost\n",
    "\n",
    "#Custom Gradient boost model for Lowess\n",
    "class GradientBoost:\n",
    "    \n",
    "    def __init__(self,model=Lowess,scaler=StandardScaler(),tau=0.5,kernel=Gaussian):  \n",
    "        self.model = model\n",
    "        self.scaler = scaler\n",
    "        self.tau = tau\n",
    "        self.kernel = kernel\n",
    "        \n",
    "    def fit(self,X,y):\n",
    "        if self.scaler:\n",
    "            self.X = self.scaler.fit_transform(X)\n",
    "            self.y = y.reshape(-1,1)\n",
    "        else:\n",
    "            self.X = X\n",
    "            self.y = y.reshape(-1,1)\n",
    "        \n",
    "        \n",
    "    def is_fitted(self):\n",
    "        try:\n",
    "            if self.X.any() and self.y.any():\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "        except:\n",
    "            raise Exception(\"Data must be fitted first\")\n",
    "        \n",
    "    def predict(self, xnew, iterations):\n",
    "        if self.is_fitted():\n",
    "            pass\n",
    "        else: \n",
    "            raise Exception(\"Data must be fitted first\")\n",
    "            \n",
    "        if self.scaler:\n",
    "            xnew = self.scaler.fit_transform(xnew)\n",
    "        \n",
    "        output = np.zeros((iterations,xnew.shape[0]))\n",
    "        for i in range(iterations):    \n",
    "            model1 = self.model(tau=self.tau, kernel=self.kernel)\n",
    "            model1.fit(self.X,self.y)\n",
    "            residuals = self.y - (model1.predict(self.X).reshape(-1,1))\n",
    "            model2 = self.model(tau=self.tau, kernel=self.kernel)\n",
    "            model2.fit(self.X,residuals)\n",
    "            output[i] = np.add(model1.predict(xnew),model2.predict(xnew))\n",
    "        return np.mean(output,axis=0)\n",
    "\n",
    "gradBoost = GradientBoost()\n",
    "\n",
    "data = pd.read_csv('../content/01intro/concrete.csv')\n",
    "y = data['strength'].values\n",
    "X = data.drop(['strength'],axis=1).values\n",
    "\n",
    "\n",
    "# Performing 10-fold cross-validation on the training data\n",
    "def KFoldProcessForTau(X,y,tau,iterations,n_quantiles,kern=Gaussian):\n",
    "    \n",
    "    gradBoost = GradientBoost(tau=tau,scaler=QuantileTransformer(n_quantiles=n_quantiles),kernel=kern)\n",
    "    model_xgboost = xgboost.XGBRFRegressor()\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = tts(X, y, test_size=0.3, random_state=42)\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    gradBoostMSES = []\n",
    "    XGBoostMSES = []\n",
    "    for train_index, val_index in kf.split(X_train):\n",
    "        X_train_fold, X_test_fold = X_train[train_index], X_train[val_index]\n",
    "        y_train_fold, y_test_fold = y_train[train_index], y_train[val_index]\n",
    "    \n",
    "        gradBoost.fit(X_train_fold, y_train_fold)\n",
    "        gradBoostYHat = gradBoost.predict(X_test_fold, iterations=iterations)\n",
    "        gradBoostMSES.append(mse(y_test_fold,gradBoostYHat.reshape(-1,1)))\n",
    "    \n",
    "        model_xgboost.fit(X_train_fold,y_train_fold)\n",
    "        XGBoostYHat = model_xgboost.predict(X_test_fold)\n",
    "        XGBoostMSES.append(mse(y_test_fold,XGBoostYHat))\n",
    "\n",
    "    print(\"Gradboost MSE is: \" + str(np.mean(gradBoostMSES)))\n",
    "    print(\"XGBoost MSE is: \" + str(np.mean(XGBoostMSES)))\n",
    "\n",
    "iterations = 2\n",
    "n_quantiles = 70\n",
    "kern = Gaussian\n",
    "#A search of tau from 0.01-1 revealed 0.25 to be fairly optimal\n",
    "tau = 0.25\n",
    "print(\"For tau of \" + str(tau) + \" and boost iterations of \" +str(iterations) + \" and n scaling quantiles of \" + str(n_quantiles) + \" for QuantileTransformer scaling\")\n",
    "KFoldProcessForTau(X,y,tau,iterations,n_quantiles,kern)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8903fc2a",
   "metadata": {},
   "source": [
    "As we can see, we have beaten XGBoost with our custom GradientBoosting class with the Gaussian kernel and two boosting iterations and tau = 0.25 and QuantileTransformer scaling with 70 quantiles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80a9cf7",
   "metadata": {},
   "source": [
    "# 2. (3 points) Based on the Usearch library, create your own class that computes the k_Nearest Neighbors for Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "7bbeb179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.67348019170473"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from usearch.index import search, MetricKind, Matches, BatchMatches\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "class CustomKNN:\n",
    "    \n",
    "    def __init__(self, n_neighbors=10, scaler=StandardScaler()):\n",
    "        self.k = n_neighbors\n",
    "        self.scaler = scaler\n",
    "        \n",
    "        \n",
    "    def fit(self,X, y):\n",
    "        if self.scaler:\n",
    "            self.X = self.scaler.fit_transform(X)\n",
    "            self.y = y\n",
    "        else:\n",
    "            self.X = X\n",
    "            self.y = y\n",
    "        \n",
    "    def is_fitted(self):\n",
    "        try:\n",
    "            if self.X.any():\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "        except:\n",
    "            raise Exception(\"Data must be fitted first\")    \n",
    "    \n",
    "    def n_closest_points(self):\n",
    "        n = self.X.shape[0]\n",
    "        \n",
    "        points_dict = {}\n",
    "        \n",
    "        for i, test_point in enumerate(self.X):\n",
    "            \n",
    "            smallest_distances = {}\n",
    "            \n",
    "            \n",
    "            distances_from_point = search(self.X, test_point,n,MetricKind.L2sq, exact=True).distances\n",
    "            indices = search(self.X, test_point,n,MetricKind.L2sq, exact=True).keys\n",
    "            for idx, distance in enumerate(distances_from_point[1:self.k]):\n",
    "                smallest_distances[indices[idx+1]] = distance\n",
    "            points_dict[i] = smallest_distances\n",
    "            \n",
    "        #Returns dictionary with key = point1 and value = another dictionary where keys are the n_neighbors closest\n",
    "        #points to point1 and the values are their distances from point1 \n",
    "        return points_dict\n",
    "    \n",
    "    def predict(self, xnew):\n",
    "        if self.scaler:\n",
    "            xnew = self.scaler.fit_transform(xnew)\n",
    "        \n",
    "        n = xnew.shape[0]\n",
    "        \n",
    "        yPreds = np.ndarray((n,1))\n",
    "        for row in xnew:\n",
    "            distances_from_point = search(self.X, row,self.k,MetricKind.L2sq, exact=True).distances\n",
    "            indices = search(self.X, row,self.k,MetricKind.L2sq, exact=True).keys\n",
    "            distanceWeights = (1/(distances_from_point))\n",
    "            yPred = distanceWeights@y[indices].reshape(-1,1)/np.sum(distanceWeights)\n",
    "            yPreds[i] = yPred\n",
    "        return yPreds\n",
    "            \n",
    "        \n",
    "        \n",
    "data = pd.read_csv('../content/01intro/concrete.csv')\n",
    "X = data.drop(['strength'],axis=1).values\n",
    "y = data['strength'].values\n",
    "custK = CustomKNN(n_neighbors=10,scaler=StandardScaler())\n",
    "defaultK = KNeighborsRegressor(n_neighbors=10)\n",
    "\n",
    "X_train, X_test, y_train, y_test = tts(X, y, test_size=0.3, random_state=42)\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "knnMses = []\n",
    "defaultMses = []\n",
    "for train_index, val_index in kf.split(X_train):\n",
    "    X_train_fold, X_test_fold = X_train[train_index], X_train[val_index]\n",
    "    y_train_fold, y_test_fold = y_train[train_index], y_train[val_index]\n",
    "    custK.fit(X_train_fold,y_train_fold)\n",
    "    defaultK.fit(X_train_fold,y_train_fold)\n",
    "    yhat1 = custK.predict(X_test_fold)\n",
    "    #print(np.column_stack([y_test_fold,yhat]))\n",
    "    yhat2 = defaultK.predict(X_test_fold)\n",
    "    knnMses.append(mse(y_test_fold, yhat2))\n",
    "    defaultMses.append(mse(y_test_fold,yhat2))\n",
    "    \n",
    "np.mean(knnMses)\n",
    "#np.mean(defaultMses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "9eec33ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cement</th>\n",
       "      <th>slag</th>\n",
       "      <th>ash</th>\n",
       "      <th>water</th>\n",
       "      <th>superplastic</th>\n",
       "      <th>coarseagg</th>\n",
       "      <th>fineagg</th>\n",
       "      <th>age</th>\n",
       "      <th>strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>79.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>61.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "      <td>40.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "      <td>41.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>360</td>\n",
       "      <td>44.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025</th>\n",
       "      <td>276.4</td>\n",
       "      <td>116.0</td>\n",
       "      <td>90.3</td>\n",
       "      <td>179.6</td>\n",
       "      <td>8.9</td>\n",
       "      <td>870.1</td>\n",
       "      <td>768.3</td>\n",
       "      <td>28</td>\n",
       "      <td>44.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>322.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>115.6</td>\n",
       "      <td>196.0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>817.9</td>\n",
       "      <td>813.4</td>\n",
       "      <td>28</td>\n",
       "      <td>31.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>148.5</td>\n",
       "      <td>139.4</td>\n",
       "      <td>108.6</td>\n",
       "      <td>192.7</td>\n",
       "      <td>6.1</td>\n",
       "      <td>892.4</td>\n",
       "      <td>780.0</td>\n",
       "      <td>28</td>\n",
       "      <td>23.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028</th>\n",
       "      <td>159.1</td>\n",
       "      <td>186.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>175.6</td>\n",
       "      <td>11.3</td>\n",
       "      <td>989.6</td>\n",
       "      <td>788.9</td>\n",
       "      <td>28</td>\n",
       "      <td>32.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>260.9</td>\n",
       "      <td>100.5</td>\n",
       "      <td>78.3</td>\n",
       "      <td>200.6</td>\n",
       "      <td>8.6</td>\n",
       "      <td>864.5</td>\n",
       "      <td>761.5</td>\n",
       "      <td>28</td>\n",
       "      <td>32.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1030 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      cement   slag    ash  water  superplastic  coarseagg  fineagg  age  \\\n",
       "0      540.0    0.0    0.0  162.0           2.5     1040.0    676.0   28   \n",
       "1      540.0    0.0    0.0  162.0           2.5     1055.0    676.0   28   \n",
       "2      332.5  142.5    0.0  228.0           0.0      932.0    594.0  270   \n",
       "3      332.5  142.5    0.0  228.0           0.0      932.0    594.0  365   \n",
       "4      198.6  132.4    0.0  192.0           0.0      978.4    825.5  360   \n",
       "...      ...    ...    ...    ...           ...        ...      ...  ...   \n",
       "1025   276.4  116.0   90.3  179.6           8.9      870.1    768.3   28   \n",
       "1026   322.2    0.0  115.6  196.0          10.4      817.9    813.4   28   \n",
       "1027   148.5  139.4  108.6  192.7           6.1      892.4    780.0   28   \n",
       "1028   159.1  186.7    0.0  175.6          11.3      989.6    788.9   28   \n",
       "1029   260.9  100.5   78.3  200.6           8.6      864.5    761.5   28   \n",
       "\n",
       "      strength  \n",
       "0        79.99  \n",
       "1        61.89  \n",
       "2        40.27  \n",
       "3        41.05  \n",
       "4        44.30  \n",
       "...        ...  \n",
       "1025     44.28  \n",
       "1026     31.18  \n",
       "1027     23.70  \n",
       "1028     32.77  \n",
       "1029     32.40  \n",
       "\n",
       "[1030 rows x 9 columns]"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
